{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# AntakIA tutorial\n",
    "***\n",
    "### Using AntakIA with the GUI!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AntakIA helps you understand and explain your _black-box_ machine-learning models, by identifying the most relevant way of segregating your dataset and the best surrogate models to apply on these freshly created regions. In this notebook, we will show you how to use the automatic dyadic-clustering algorithm of AntakIA.\n",
    "\n",
    "> This notebook is a tutorial on how to use AntakIA with the GUI. If you want to use the GUI, please refer to the [AntakIA without GUI tutorial](antakia_CH_no_gui.ipynb).\n",
    "> \n",
    "> For more information about AntakIA, please refer to the [AntakIA documentation](https://ai-vidence.github.io/antakia/) or go to [AI-vidence's website](https://ai-vidence.com/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__In this notebook, you will learn how to:__\n",
    "- Create a dataset object from a CSV file\n",
    "- Instanciate an AntakIA object\n",
    "- Run the GUI to explore the dataset, the model, define regions and apply sub-models\n",
    "- Visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context :\n",
    "\n",
    "__Let's pretend that we are a real estate agent and that we want to predict the price of a house based on its characteristics.__ We have a dataset of more than 20000 blocks of houses, each block being described by 8 features (e.g. medium income of the owners, number of rooms, etc.). We also have the price of each block of houses. We already trained a machine-learning model (in our case, a simple XGBoost) that will predict the price of a house based on its characteristics. This is very helpful to estimate the price of a house that we want to sell !\n",
    "\n",
    "__The main issue is the following :__ we want to explain to our customers why their house is worth a certain price. We can't just show them the machine-learning model, because it is a _black-box_ model. We need to find a way to explain the price of a house based on its characteristics. This is where AntakIA comes in handy !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, our dataset. We use [this Californian housing dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) from Scikit-learn repo.\n",
    "\n",
    "It the `data` folder of this repository, you'll see `california_housing.csv`: it already has its SHAP values computed so you won't have to wait for their calculation.\n",
    "âš  Check you have Git Large File Storage (LGS) installed to use our dataset, see : https://git-lfs.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../data/california_housing.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mdrop([\u001b[39m'\u001b[39;49m\u001b[39mUnnamed: 0\u001b[39;49m\u001b[39m'\u001b[39;49m], axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# If you prefer to start with the genuine fresh dataset  :\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# from sklearn.datasets import fetch_california_housing\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# df=fetch_california_housing(as_frame=True).frame\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/antakia/lib/python3.10/site-packages/pandas/core/frame.py:5258\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5111\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5112\u001b[0m     labels: IndexLabel \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5119\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5120\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5121\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5122\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5123\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5256\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5257\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5259\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5260\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5261\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5262\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5263\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5264\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5265\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5266\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/antakia/lib/python3.10/site-packages/pandas/core/generic.py:4549\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4547\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4548\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4549\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4551\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4552\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Documents/antakia/lib/python3.10/site-packages/pandas/core/generic.py:4591\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4589\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4590\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4591\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4592\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4594\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4595\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/antakia/lib/python3.10/site-packages/pandas/core/indexes/base.py:6699\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6697\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6698\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(labels[mask])\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6700\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6701\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/california_housing.csv').drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "# If you prefer to start with the genuine fresh dataset  :\n",
    "# from sklearn.datasets import fetch_california_housing\n",
    "# df=fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning a bit our data, we want to specifically focus on __San Francisco__ and its surroundings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers:\n",
    "df = df.loc[df['Population']<10000] \n",
    "df = df.loc[df['AveOccup']<6]\n",
    "df = df.loc[df['AveBedrms']<1.5]\n",
    "df = df.loc[df['HouseAge']<50]\n",
    "\n",
    "# Only San Francisco :\n",
    "df = df.loc[(df['Latitude']<38.07)&(df['Latitude']>37.2)]\n",
    "df = df.loc[(df['Longitude']>-122.5)&(df['Longitude']<-121.75)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we already computed some explanatory values (in our case, SHAP values) and saved them in the CSV file. This is not necessary, as AntakIA can do it, but it will save us some computation time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:8] # the dataset\n",
    "Y = df.iloc[:,9] # the target variable\n",
    "SHAP = df.iloc[:,[10,11,12,13,14,15,16,17]] # the SHAP values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a trained XGBoost model that we will use to predict the price of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(random_state = 9)\n",
    "model.fit(X, Y)\n",
    "print('model fitted')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Let's now import `antakia`!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import antakia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Creating the dataset object\n",
    "\n",
    "We first use the [`Dataset`](https://ai-vidence.github.io/antakia/documentation/dataset/) class to create a dataset object. This object will be used to store the data and the machine-learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = antakia.Dataset(X, model = model, y=Y)\n",
    "print(f'Size of the data we want to explore: {len(dataset)} lines')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating the AntakIA object\n",
    "We then use the [`AntakIA`](https://ai-vidence.github.io/antakia/documentation/antakia/) class to create an AntakIA object. This is the main object of the package!\n",
    "This is where we import our explanatory values (in our case, SHAP values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atk = antakia.AntakIA(dataset, import_explanation = SHAP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Launching the GUI!\n",
    "We can now launch the GUI! We will use it to manually define regions, explore our data and model, or run the automatic dyadic-clustering algorithm.\n",
    "\n",
    "Before using the GUI, we recommend you to do the following things:\n",
    "- Take a look at its documentation [here](https://ai-vidence.github.io/antakia/documentation/gui/). `GUI` is a specific AntakIA object!\n",
    "- Read the [User guide](https://ai-vidence.github.io/antakia/usage/) section of the documentation.\n",
    "- Watch the video tutorials on [AI-vidence's website](https://ai-vidence.com/) or on [YouTube](https://www.youtube.com/@AI-vidence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk.startGUI()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__You may retrieve your results by using the following commands:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(atk.gui.getSelection()) # the selection is an attribute of the GUI. It is a Potato object!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk.getRegions() # get the regions created using the GUI. A region is a list of antakia Potatoes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk.getSaves() # get the saves created using the GUI. A save is a list of regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atk.getExplanations() # get the explanation values (Imported, SHAP, LIME), so as to save them locally and use them later. Their computation can be long!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it ! You now know how to use AntakIA with GUI. If you don't want to use the GUI, please refer to the [AntakIA with no GUI tutorial](antakia_no_gui.ipynb).\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List if usefull links\n",
    "\n",
    "- [AntakIA documentation](https://ai-vidence.github.io/antakia/) - The official documentation of AntakIA\n",
    "- [AntakIA GitHub repository](https://github.com/AI-vidence/antakia/tree/main) - The GitHub repository of AntakIA. Do not forget to __star__ it if you like it!\n",
    "- [AntakIA video tutorials](https://www.youtube.com/@AI-vidence) - The YouTube channel of AI-vidence, with video tutorials on AntakIA!\n",
    "- [AI-vidence's website](https://ai-vidence.com/) - The website of AI-vidence, the company behind AntakIA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/AI-vidence/antakia/main/docs/img/Logo-AI-vidence.png\" alt=\"AI-vidence\" width=\"200px\"/> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "antakia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
