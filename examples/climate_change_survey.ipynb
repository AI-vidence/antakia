{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANTAKIA : A New Tool to Aquire Knowledge form AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T14:24:05.957714Z",
     "start_time": "2023-11-30T14:24:00.828993Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import catboost\n",
    "from antakia.utils.examples import fetch_dataset\n",
    "from antakia.antakia import AntakIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T14:24:06.013570Z",
     "start_time": "2023-11-30T14:24:05.959950Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = fetch_dataset(\"climate_change_survey\")[\"X_train\"].drop('Unnamed: 0', axis=1)\n",
    "X_test = fetch_dataset(\"climate_change_survey\")[\"X_test\"].drop('Unnamed: 0', axis=1)\n",
    "y_train = fetch_dataset(\"climate_change_survey\")[\"y_train\"].drop('Unnamed: 0', axis=1)\n",
    "y_test = fetch_dataset(\"climate_change_survey\")[\"y_test\"].drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Catboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T14:24:07.626339Z",
     "start_time": "2023-11-30T14:24:06.028270Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = catboost.CatBoostRegressor(max_depth=5)\n",
    "model.fit(X_train, y_train, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "print('MAE', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE', mean_squared_error(y_test, y_pred))\n",
    "print('R2', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train an Explainable Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "exp_model = LinearRegression()\n",
    "exp_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "y_pred = exp_model.predict(X_test)\n",
    "print('MAE', mean_absolute_error(y_test, y_pred))\n",
    "print('MSE', mean_squared_error(y_test, y_pred))\n",
    "print('R2', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T14:24:37.266548Z",
     "start_time": "2023-11-30T14:24:08.643860Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "atk = AntakIA(X_train.iloc[:5000,:], y_train.iloc[:5000,:], model)\n",
    "atk.start_gui()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposition de déroulé\n",
    "## présentation de l'outil et son objectif :\n",
    "- on cherche à mettre en évidence des segments dans les données avec des comportements similaires, qu'on pourra utiliser ensuite, soit d'un point de vue marketing soit pour mettre en place des modèles simples/interprétable de prédiction des données\n",
    "- dans tous les cas cette analyse nous permettra de mieux comprendre nos données/la population à qui on a affaire\n",
    "- elle sinscrit en complément à une EDA (Exploratory data analysis)\n",
    "\n",
    "## déroulé du notebook :\n",
    "- executer toutes les cellules (on se limite pour l'instant à 5K points (sinon changer la variable d'env))\n",
    "\n",
    "### présentation des deux espaces,\n",
    "- à gauche ce sont les données projetées en deux dimension, avec une petite cuisine maison,\n",
    "- à droite, la même chose pour les valeur de shapley\n",
    "\n",
    "Nous avons donc l'espace de Valeurs, et l'espace des Explications, \n",
    "\n",
    "une petite analogie, à gauche, ce sont les données telles que nous les voyons, à droite, telles que le modèle les voit, telles qu'elles influent sur le résultat.\n",
    "\n",
    "La couleur, c'est la valeur de la variable cible. on voit ici une forte inhomogénéité de cette valeur, c'est assez fréquent dans les données de comportement humain, où le bruit est assez élévé vis à vis de la tendance. \n",
    "\n",
    "^y : on voit au contraire ici que les couleurs sont beaucoup plus lisses, c'est plutot un bon signe, signe que le modèle a appris la tendance, pas le bruit\n",
    "\n",
    "résidus : on retrouve notre bruit ici, c'est cohérent avec nos observations précédentes\n",
    "\n",
    "### mise en place des règles :\n",
    "- on selectionne un paté de données, puis on regarde en détail la règle qui en ressort\n",
    "- on modifie la règle et on regarde en quoi ça inclus d'autres points / patés de points\n",
    "- on valide la règle\n",
    "- on peut recommencer avec une autre règle dans l'ES ?? si oui il faut être clair de ce qu'on fait (valider le bon fonctionnement avant)\n",
    "\n",
    "### régionalisation :\n",
    "- on demande à l'algo de clustériser le reste (en taille auto c'est très bien)\n",
    "- on peut refaire avec d'autres nombres de régions\n",
    "- blabla sur les règles qui en ressortent (même si on en les voit pas)\n",
    "\n",
    "### substitution : \n",
    "- on passe à l'étape substitution, on parcours un peu les modèles proposés,\n",
    "- on voit que certains modèles marchent bien, d'autres très mal, on choisit le meilleur qui n'est le custom\n",
    "- on attire l'attention de l'auditoire que pour l'instant la comparaison n'est pas à l'avantage des modèles explicables parce que le jeu de test de ces modèles est en fait un jeu d'entrainement du modèle custom. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
