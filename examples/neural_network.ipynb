{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from numba.core.errors import NumbaDeprecationWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=NumbaDeprecationWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../data/mnist/mnist_train.csv')\n",
    "data_test = pd.read_csv('../data/mnist/mnist_test.csv')\n",
    "\n",
    "N_train = 6000\n",
    "n_train = N_train/len(data_train)\n",
    "N_test = 1000\n",
    "n_test = N_test/len(data_test)\n",
    "\n",
    "data_train = data_train.sample(frac=n_train, random_state=9)\n",
    "data_test = data_test.sample(frac=n_test, random_state=9)\n",
    "\n",
    "X_train = data_train.iloc[:, 1:].values\n",
    "y_train = data_train.iloc[:, 0].values\n",
    "\n",
    "X_test = data_test.iloc[:, 1:].values\n",
    "y_test = data_test.iloc[:, 0].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the hyperparameters for data creation\n",
    "NUM_CLASSES = 10\n",
    "NUM_FEATURES = 28*28\n",
    "RANDOM_SEED = 9\n",
    "\n",
    "\n",
    "# 2. Turn data into tensors\n",
    "X_train = torch.from_numpy(X_train).type(torch.float)\n",
    "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "X_test = torch.from_numpy(X_test).type(torch.float)\n",
    "y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "print(X_train[:5], y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_features, output_features, hidden_units):\n",
    "        super().__init__()\n",
    "        self.linear_layer_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
    "            nn.ReLU(), # <- does our dataset require non-linear layers? (try uncommenting and see if the results change)\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.ReLU(), # <- does our dataset require non-linear layers? (try uncommenting and see if the results change)\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_features), # how many classes are there?\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_layer_stack(x)\n",
    "\n",
    "# Create an instance of BlobModel and send it to the target device\n",
    "model = Model(input_features=NUM_FEATURES, \n",
    "                    output_features=NUM_CLASSES, \n",
    "                    hidden_units=5)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Set number of epochs\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    ### Training\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    y_logits = model(X_train) # model outputs raw logits \n",
    "    y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1) # go from logits -> prediction probabilities -> prediction labels\n",
    "    # print(y_logits)\n",
    "    # 2. Calculate loss and accuracy\n",
    "    loss = loss_fn(y_logits, y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, y_pred=y_pred)\n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    ### Testing\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model(X_test)\n",
    "        test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
    "        # 2. Calculate test loss and accuracy\n",
    "        test_loss = loss_fn(test_logits, y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,y_pred=test_pred)\n",
    "\n",
    "    if epoch % (epochs/10) == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test Loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape)\n",
    "print(model.linear_layer_stack[0].weight.shape)\n",
    "first_layer = np.array(model.linear_layer_stack[1](torch.tensor(np.dot(X_test, model.linear_layer_stack[0].weight.detach().numpy().T))))\n",
    "print(first_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(first_layer)\n",
    "new_data.columns = ['Neurone_1', 'Neurone_2', 'Neurone_3', 'Neurone_4', 'Neurone_5']\n",
    "display(new_data.head())\n",
    "print(new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image(ligne):\n",
    "    return np.array(ligne).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(18, 5.5))\n",
    "columns = 5\n",
    "rows = 1\n",
    "\n",
    "for i in range(columns*rows):\n",
    "    a = np.array(X_test.T)\n",
    "    b = np.array(new_data.iloc[:,i])\n",
    "    c = np.dot(a,b)/sum(b)\n",
    "    m = np.mean(c)\n",
    "    mon_image = image(c)\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.title('Neurone '+str(i+1))\n",
    "    plt.imshow(mon_image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "fig1 = plt.figure(figsize=(18, 5.5))\n",
    "for i in range(columns*rows):\n",
    "    a = np.array(X_test.T)\n",
    "    b = np.array(new_data.iloc[:,i])\n",
    "    c = np.dot(a,b)/sum(b)\n",
    "    m = np.mean(c)\n",
    "    l = []\n",
    "    for j in range(len(c)):\n",
    "        if c[j] > m:\n",
    "            l.append(255)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    mon_image = image(l)\n",
    "    fig1.add_subplot(rows, columns, i+1)\n",
    "    plt.title('Neurone '+str(i+1))\n",
    "    plt.imshow(mon_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def predict(X):\n",
    "        retour = np.dot(X, model.linear_layer_stack[2].weight.detach().numpy().T)\n",
    "        retour = np.array(model.linear_layer_stack[3](torch.tensor(retour)))\n",
    "        retour = np.dot(retour, model.linear_layer_stack[4].weight.detach().numpy().T)\n",
    "        retour = torch.softmax(torch.tensor(retour), dim=1).argmax(dim=1)\n",
    "        return np.array(retour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Précision du modèle : {round(list(New_model.predict(first_layer)-np.array(y_test)).count(0)/len(y_test)*100,6)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(new_data)\n",
    "y = pd.Series(y_test)\n",
    "new_model = New_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import antakia\n",
    "explain = antakia.Xplainer(X = X, Y = y, model = new_model)\n",
    "\n",
    "import sklearn\n",
    "import imodels\n",
    "\n",
    "models = [\n",
    "    sklearn.tree.DecisionTreeClassifier(max_depth=3),\n",
    "    sklearn.linear_model.LinearRegression()\n",
    "]\n",
    "\n",
    "display(explain.interface(explanation = \"SHAP\", models = models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = np.array(explain.result()[0]['X'])\n",
    "new_y = np.array(explain.result()[0]['y'])\n",
    "new_model = explain.result()[0]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(new_X, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new_pred = [round(new_model.predict(new_X)[i]) for i in range(len(new_X))]\n",
    "y_new_pred = np.array(y_new_pred)\n",
    "print(list(y_new_pred - new_y)[:10])\n",
    "print(y_new_pred[:10])\n",
    "print(new_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
